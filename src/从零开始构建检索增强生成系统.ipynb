{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab688ab-ca29-42f5-9d2c-adc58a3ef261",
   "metadata": {},
   "source": [
    "# RAGç³»ç»ŸåŸºç¡€:RAGç³»ç»ŸåŸºç¡€ï¼šä»é›¶å¼€å§‹æ„å»ºæ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ\n",
    "\n",
    "RAG ç³»ç»Ÿè§£å†³çš„é—®é¢˜ï¼š **æ¨¡å‹è®­ç»ƒçŸ¥è¯†æˆªè‡³æ—¥æœŸ**å’Œ**é¢†åŸŸä¸“ä¸šçŸ¥è¯†çš„ç¼ºä¹**\n",
    "\n",
    "ä¾‹å¦‚ï¼šåœ¨ä¼ä¸šä¸­è¯¢é—® æˆ‘ä»¬å…¬å¸2025å¹´Q3å­£åº¦çš„é”€å”®æ•°æ®æ˜¯å¤šå°‘ï¼Ÿï¼ˆå…¬å¸å†…éƒ¨æ–‡ä»¶ï¼‰\n",
    "\n",
    "# RAGç³»ç»Ÿçš„ç»„æˆ\n",
    "\n",
    "ä¸€ä¸ªå®Œæ•´çš„RAGç³»ç»Ÿç”±ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼š\n",
    "\n",
    "ç´¢å¼•é˜¶æ®µ Indexing -> æ£€ç´¢é˜¶æ®µ Retrieval -> ç”Ÿæˆé˜¶æ®µ Generation\n",
    "\n",
    "## Indexing\n",
    "\n",
    "å°†æ–‡æ¡£è½¬æ¢ä¸ºå¯æœç´¢çš„å‘é‡æ ¼å¼\n",
    "\n",
    "æ ¸å¿ƒæ­¥éª¤ï¼š\n",
    "    1. æ–‡æ¡£åŠ è½½ Document Loading\n",
    "    2. æ–‡æœ¬åˆ†å— Text Splitting\n",
    "    3. å‘é‡åŒ– Vectorization\n",
    "    4. å­˜å‚¨ Storage\n",
    "\n",
    "## Retrieval\n",
    "\n",
    "æ ¹æ®ç”¨æˆ·æŸ¥è¯¢æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ\n",
    "\n",
    "æ ¸å¿ƒæ­¥éª¤ï¼š\n",
    "    1. æŸ¥è¯¢å‘é‡åŒ–\n",
    "    2. ç›¸ä¼¼åº¦è®¡ç®—\n",
    "    3. ç»“æœæ’åº\n",
    "\n",
    "## Generation\n",
    "\n",
    "åŸºäºæ£€ç´¢åˆ°çš„ä¿¡æ¯ç”Ÿæˆå‡†ç¡®ç­”æ¡ˆ\n",
    "\n",
    "æ ¸å¿ƒæ­¥éª¤ï¼š\n",
    "    1. æ„å»ºæç¤ºè¯\n",
    "    2. LLMç”Ÿæˆ\n",
    "    3. ç­”æ¡ˆè¿”å›"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# é…ç½®ç¯å¢ƒï¼Œå¯¼å…¥æ ¸å¿ƒåŒ…",
   "id": "206302ed52cacd53"
  },
  {
   "cell_type": "code",
   "id": "866fe32c-9ce8-42b6-8eea-9e5eabfcb519",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T08:17:02.675475600Z",
     "start_time": "2026-01-08T08:17:02.636002200Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "\n",
    "from langchain_qwq import ChatQwen\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "9758bf9a-9445-4854-88a7-10d9e6beafa9",
   "metadata": {},
   "source": [
    "# ç´¢å¼• Indexing - æ„å»ºçŸ¥è¯†åº“\n",
    "æ ¸å¿ƒæ­¥éª¤ï¼š\n",
    "\n",
    "1. æ–‡æ¡£åŠ è½½ Document Loading\n",
    "2. æ–‡æœ¬åˆ†å— Text Splitting\n",
    "3. å‘é‡åŒ– Vectorization\n",
    "4. å­˜å‚¨ Storage"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## æ­¥éª¤1ï¼šæ–‡æ¡£åŠ è½½",
   "id": "29e4427a1b4e2697"
  },
  {
   "cell_type": "code",
   "id": "ab5e8963-71cf-4b8b-99db-a1fa9f184b90",
   "metadata": {},
   "source": [
    "# æ­¥éª¤1ï¼šé¦–å…ˆéœ€è¦åŠ è½½æ–‡æ¡£ã€‚LangChainæ”¯æŒå¤šç§æ–‡æ¡£æº\n",
    "from langchain_community.document_loaders import(\n",
    "    WebBaseLoader,      # ç½‘é¡µ\n",
    "    PyPDFLoader,        # PDF\n",
    "    TextLoader,         # æ–‡æœ¬æ–‡ä»¶\n",
    "    DirectoryLoader,    # ç›®å½•\n",
    "    CSVLoader,          # CSV\n",
    ")\n",
    "\n",
    "# Exa: Loading Webpage\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"åŠ è½½äº† {len(docs)} ä¸ªæ–‡æ¡£\")\n",
    "print(f\"ç¬¬ä¸€ä¸ªæ–‡æ¡£é•¿åº¦ï¼š {(len(docs[0].page_content))} å­—ç¬¦\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## æ­¥éª¤2ï¼šæ–‡æœ¬åˆ†å—\n",
    "\n",
    "ä¸ºä»€ä¹ˆéœ€è¦åˆ†å—ï¼Ÿ\n",
    "1. LLMä¸Šä¸‹æ–‡é™åˆ¶ï¼šå¤§å¤šæ•°LLMæœ‰æœ€å¤§tokené™åˆ¶ï¼ˆå¦‚GPT-4çš„8K/32Kï¼‰\n",
    "2. æé«˜æ£€ç´¢ç²¾åº¦ï¼šå°å—æ–‡æœ¬æ›´å®¹æ˜“åŒ¹é…ç‰¹å®šæŸ¥è¯¢\n",
    "3. é™ä½æˆæœ¬ï¼šåªæ£€ç´¢å’Œå¤„ç†ç›¸å…³éƒ¨åˆ†\n",
    "\n",
    "ä¸åŒåˆ†å—ç­–ç•¥\n",
    "```python\n",
    "# å­—ç¬¦åˆ†å—ï¼ˆæœ€åŸºç¡€ï¼‰\n",
    "CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# Tokenåˆ†å—ï¼ˆç²¾ç¡®æ§åˆ¶tokenæ•°é‡ï¼‰\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "TokenTextSplitter(chunk_size=256, chunk_overlap=50)\n",
    "\n",
    "# è¯­ä¹‰åˆ†å—ï¼ˆåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "SemanticChunker(OpenAIEmbeddings())\n",
    "\n",
    "# é€’å½’åˆ†å—ï¼ˆæ™ºèƒ½è¯†åˆ«æ®µè½ï¼‰\n",
    "RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # ä¼˜å…ˆæŒ‰æ®µè½åˆ†å‰²\n",
    ")\n",
    "```"
   ],
   "id": "35b0606d51193c"
  },
  {
   "cell_type": "code",
   "id": "a6868dfc-79ba-4587-a6bb-019c4655d129",
   "metadata": {},
   "source": [
    "# åˆ›å»ºæ–‡æœ¬åˆ†å—å™¨\n",
    "# é€’å½’åˆ†å—ï¼ˆæ™ºèƒ½è¯†åˆ«æ®µè½ï¼‰\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,            # æ¯å—æœ€å¤§å­—ç¬¦æ•° æ¨èå€¼ 500-1500ï¼Œå¤ªå° -> ä¸Šä¸‹æ–‡ä¸è¶³ï¼Œå¤ªå¤§ -> åŒ¹é…ä¸ç²¾å‡†\n",
    "    chunk_overlap = 200,          # å—ä¹‹é—´çš„é‡å  10-20% å¤§å°ï¼Œä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§\n",
    "    length_function = len,        # é•¿åº¦è®¡ç®—å‡½æ•°\n",
    "    is_separator_regex = False,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # åˆ†éš”ç¬¦ï¼šä¼˜å…ˆæŒ‰æ®µè½åˆ†å‰²ï¼Œæ®µè½ > è¡Œ > è¯\n",
    ")\n",
    "\n",
    "# åˆ†å—æ–‡æ¡£\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"åŸå§‹æ–‡æ¡£: {len(docs)} ä¸ª\")\n",
    "print(f\"åˆ†å—å: {len(splits)} ä¸ª\")\n",
    "print(f\"\\nç¬¬ä¸€ä¸ªåˆ†å—ç¤ºä¾‹:\\n{splits[0].page_content[:30]}...\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## æ­¥éª¤3ï¼šå‘é‡åŒ–\n",
    "å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­¦å‘é‡ï¼Œè¿™æ˜¯è¯­ä¹‰æœç´¢çš„æ ¸å¿ƒ"
   ],
   "id": "e4031d155c330b18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# åˆ›å»ºåµŒå…¥æ¨¡å‹\n",
    "embeddings_model = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v4\",\n",
    ")\n",
    "\n",
    "# Exa: å‘é‡åŒ–ä¸€æ®µæ–‡å­—\n",
    "text = \"RAGæ˜¯ä¸€ç§å¼ºå¤§çš„AIæŠ€æœ¯\"\n",
    "new_vector_text = embeddings_model.embed_query(text)\n",
    "\n",
    "print(f\"æ–‡æœ¬: {text}\")\n",
    "print(f\"å‘é‡ç»´åº¦: {len(new_vector_text)}\")\n",
    "print(f\"å‘é‡å‰5ä¸ªå€¼: {new_vector_text[:5]}\")"
   ],
   "id": "379646119ed99321",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## æ­¥éª¤4ï¼šå­˜å‚¨\n",
    "\n",
    "å‘é‡æ•°æ®åº“é€‰æ‹©ï¼š\n",
    "\n",
    "| **æ•°æ®åº“**  | **ç±»å‹** | **ä¼˜åŠ¿**      | **é€‚ç”¨åœºæ™¯**   |\n",
    "|----------|--------|-------------|------------|\n",
    "| Chroma   | åµŒå…¥å¼    | ç®€å•æ˜“ç”¨ï¼Œæ— éœ€é¢å¤–æœåŠ¡ | å¼€å‘ã€å°è§„æ¨¡åº”ç”¨ â­ |\n",
    "| Pinecone | äº‘æœåŠ¡    | é«˜æ€§èƒ½ï¼Œæ‰˜ç®¡æœåŠ¡    | ç”Ÿäº§ç¯å¢ƒ       |\n",
    "| Weaviate | è‡ªå»º     | åŠŸèƒ½ä¸°å¯Œï¼Œå¼€æº     | å¤§è§„æ¨¡éƒ¨ç½²      |\n",
    "| FAISS    | åº“      | é€Ÿåº¦å¿«ï¼ŒMetaå¼€æº  | ç ”ç©¶å’ŒåŸå‹      |"
   ],
   "id": "8a9afe5e44844b0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# åˆ›å»ºå‘é‡æ•°æ®åº“\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,           # åˆ†å—åçš„æ–‡æ¡£\n",
    "    embedding=embeddings_model,       # åµŒå…¥æ¨¡å‹\n",
    "    persist_directory=\"./chroma_db\"  # æŒä¹…åŒ–ç›®å½•\n",
    ")\n",
    "\n",
    "print(f\"âœ… å‘é‡æ•°æ®åº“åˆ›å»ºæˆåŠŸï¼\")\n",
    "print(f\"   å­˜å‚¨äº† {len(splits)} ä¸ªæ–‡æ¡£å—\")\n",
    "print(f\"   æŒä¹…åŒ–è·¯å¾„: ./chroma_db_\")"
   ],
   "id": "44507fc0a74a102f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## å®Œæ•´æµç¨‹ + å°è£…",
   "id": "35f222dac569c051"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T07:16:28.640511500Z",
     "start_time": "2026-01-08T07:16:18.385633800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_vectorstore(url: str, chunk_size: int = 1000):\n",
    "    \"\"\"åˆ›å»ºå‘é‡æ•°æ®åº“\"\"\"\n",
    "\n",
    "    # 1. åŠ è½½æ–‡æ¡£\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "\n",
    "    # 2. åˆ†å—\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=int(chunk_size * 0.1)\n",
    "    )\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    # 3. å‘é‡åŒ–å¹¶å­˜å‚¨\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=splits,\n",
    "        embedding=DashScopeEmbeddings(model=\"text-embedding-v4\"),\n",
    "        persist_directory=f\"./chroma_db_{url.split('/')[-1]}\"\n",
    "    )\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "# ä½¿ç”¨\n",
    "vectorstore = create_vectorstore(\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
    ")"
   ],
   "id": "479005c827d8d42d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# æ£€ç´¢ Retrieval -æ‰¾åˆ°ç›¸å…³ä¿¡æ¯",
   "id": "ab897d886db3e3ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T07:19:48.887200Z",
     "start_time": "2026-01-08T07:19:48.453735100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# åˆ›å»ºæ£€ç´¢å™¨\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",  # ç›¸ä¼¼åº¦æœç´¢\n",
    "    search_kwargs={\"k\": 3}     # è¿”å›å‰3ä¸ªç»“æœ\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œæ£€ç´¢\n",
    "query = \"ä»€ä¹ˆæ˜¯Agentï¼Ÿ\"\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "# æŸ¥çœ‹ç»“æœ\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"\\nğŸ“„ ç»“æœ {i}:\")\n",
    "    print(f\"å†…å®¹: {doc.page_content[:200]}...\")\n",
    "    print(f\"æ¥æº: {doc.metadata.get('source', 'N/A')}\")"
   ],
   "id": "f5b57e9ef844daaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“„ ç»“æœ 1:\n",
      "å†…å®¹: Resources:\n",
      "1. Internet access for searches and information gathering.\n",
      "2. Long Term memory management.\n",
      "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
      "4. File output.\n",
      "\n",
      "Performance Evaluation:...\n",
      "æ¥æº: https://lilianweng.github.io/posts/2023-06-23-agent/\n",
      "\n",
      "ğŸ“„ ç»“æœ 2:\n",
      "å†…å®¹: Resources:\n",
      "1. Internet access for searches and information gathering.\n",
      "2. Long Term memory management.\n",
      "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
      "4. File output.\n",
      "\n",
      "Performance Evaluation:...\n",
      "æ¥æº: https://lilianweng.github.io/posts/2023-06-23-agent/\n",
      "\n",
      "ğŸ“„ ç»“æœ 3:\n",
      "å†…å®¹: Prompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\n",
      "\n",
      "\n",
      "Planning & Reacting: tr...\n",
      "æ¥æº: https://lilianweng.github.io/posts/2023-06-23-agent/\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ç”Ÿæˆ Generation -äº§ç”Ÿç­”æ¡ˆ",
   "id": "ed8a7c0323cb1cf6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T08:55:59.125057600Z",
     "start_time": "2026-01-08T08:55:38.394147300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# åˆ›å»ºLLM\n",
    "llm = ChatQwen(\n",
    "    model=\"qwen-plus\",\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    temperature=0  # 0 = æ›´ç²¾ç¡®, 1 = æ›´æœ‰åˆ›æ„\n",
    ")\n",
    "\n",
    "# å®šä¹‰ prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹èƒŒæ™¯ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\\n\\nèƒŒæ™¯ä¿¡æ¯ï¼š\\n{context}\"),\n",
    "    (\"human\", \"{query}\"),\n",
    "])\n",
    "\n",
    "\n",
    "# 1. å®šä¹‰æ ¼å¼åŒ–å‡½æ•°\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# 2. å®šä¹‰å¹¶è¡Œè¿è¡Œçš„æ­¥éª¤ï¼ˆæ—¢ä¿ç•™æ–‡æ¡£å¯¹è±¡ï¼Œåˆç”Ÿæˆ prompt éœ€è¦çš„å­—ç¬¦ä¸²ï¼‰\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"query\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "# 3. å®šä¹‰ç”Ÿæˆç­”æ¡ˆçš„åˆ†æ”¯\n",
    "qa_chain = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"]))) # è¿™é‡ŒåªæŠŠ context è½¬å­—ç¬¦ä¸²ç»™ prompt ç”¨\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 4. åˆå¹¶é“¾ï¼šå…ˆæ£€ç´¢ï¼Œç„¶åæŠŠç»“æœç”± assign åŠ åˆ°å­—å…¸é‡Œ\n",
    "final_chain = setup_and_retrieval.assign(answer=qa_chain)\n",
    "\n",
    "# 5. æé—®\n",
    "query = \"ä»€ä¹ˆæ˜¯Agentï¼Ÿå®ƒæœ‰ä»€ä¹ˆèƒ½åŠ›ï¼Ÿ\"\n",
    "result = final_chain.invoke(query)\n",
    "\n",
    "# 6. ç»“æœç°åœ¨æ˜¯ä¸€éƒ¨å­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰ä¿¡æ¯\n",
    "print(\"é—®é¢˜:\", result[\"query\"])\n",
    "print(\"å›ç­”:\", result[\"answer\"])\n",
    "print(\"æ¥æº:\", result[\"context\"]) # è¿™é‡Œå°±æ˜¯ source_documents"
   ],
   "id": "8b683852574cca4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å›ç­”: ä»€ä¹ˆæ˜¯Agentï¼Ÿå®ƒæœ‰ä»€ä¹ˆèƒ½åŠ›ï¼Ÿ\n",
      "å›ç­”: **ä»€ä¹ˆæ˜¯ Agentï¼Ÿ**\n",
      "\n",
      "åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸï¼Œ**Agentï¼ˆæ™ºèƒ½ä»£ç†ï¼‰** æ˜¯ä¸€ä¸ªèƒ½å¤Ÿæ„ŸçŸ¥ç¯å¢ƒã€è¿›è¡Œå†³ç­–å¹¶é‡‡å–è¡ŒåŠ¨ä»¥å®ç°ç‰¹å®šç›®æ ‡çš„è‡ªä¸»å®ä½“ã€‚å®ƒå¯ä»¥æ˜¯ä¸€ä¸ªè½¯ä»¶ç¨‹åºã€æœºå™¨äººï¼Œæˆ–æ›´å¹¿æ³›åœ°æŒ‡ä»»ä½•å…·å¤‡ä¸€å®šâ€œæ™ºèƒ½â€è¡Œä¸ºçš„ç³»ç»Ÿã€‚\n",
      "\n",
      "å½“æåˆ° **LLM-powered Agentï¼ˆå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ™ºèƒ½ä½“ï¼‰** æ—¶ï¼Œå®ƒæŒ‡çš„æ˜¯ä»¥å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ GPTã€é€šä¹‰åƒé—®ç­‰ï¼‰ä¸ºæ ¸å¿ƒçš„å¤§è„‘ï¼Œç»“åˆå¤–éƒ¨å·¥å…·å’Œè®°å¿†ç³»ç»Ÿï¼Œå½¢æˆçš„ä¸€ä¸ª**è‡ªä¸»å®Œæˆä»»åŠ¡çš„æ™ºèƒ½ç³»ç»Ÿ**ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### **Agent çš„æ ¸å¿ƒèƒ½åŠ›**\n",
      "\n",
      "ä¸€ä¸ªå…¸å‹çš„ LLM Agent å…·å¤‡ä»¥ä¸‹å››å¤§æ ¸å¿ƒèƒ½åŠ›ï¼š\n",
      "\n",
      "#### 1. **æ„ŸçŸ¥ä¸ç†è§£ï¼ˆPerception & Understandingï¼‰**\n",
      "- èƒ½å¤Ÿæ¥æ”¶ç”¨æˆ·æŒ‡ä»¤ã€ç¯å¢ƒè¾“å…¥ï¼ˆå¦‚æ–‡æœ¬ã€æ–‡ä»¶ã€ç½‘é¡µå†…å®¹ç­‰ï¼‰ã€‚\n",
      "- åˆ©ç”¨è¯­è¨€æ¨¡å‹çš„å¼ºå¤§è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œè§£ææ„å›¾ã€æå–å…³é”®ä¿¡æ¯ã€‚\n",
      "\n",
      "> âœ… ç¤ºä¾‹ï¼šä½ å‘Šè¯‰ Agent â€œå¸®æˆ‘æŸ¥ä¸€ä¸‹ä»Šå¤©åŒ—äº¬çš„å¤©æ°”â€ï¼Œå®ƒèƒ½ç†è§£â€œä»Šå¤©â€ã€â€œåŒ—äº¬â€ã€â€œå¤©æ°”â€è¿™äº›å…³é”®è¯åŠå…¶å…³ç³»ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "#### 2. **è§„åˆ’ä¸æ¨ç†ï¼ˆPlanning & Reasoningï¼‰**\n",
      "- å¯å°†å¤æ‚ä»»åŠ¡æ‹†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œåˆ¶å®šæ‰§è¡Œè®¡åˆ’ã€‚\n",
      "- åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼Œå¤„ç†å¼‚å¸¸æˆ–æ–°æƒ…å†µã€‚\n",
      "\n",
      "> âœ… ç¤ºä¾‹ï¼šè¦â€œå†™ä¸€ä»½å…³äºæ–°èƒ½æºæ±½è½¦å¸‚åœºçš„åˆ†ææŠ¥å‘Šâ€ï¼ŒAgent ä¼šè‡ªåŠ¨è§„åˆ’ä¸ºï¼š\n",
      "> - æœç´¢æœ€æ–°è¡Œä¸šæ•°æ®\n",
      "> - åˆ†æç«äº‰æ ¼å±€\n",
      "> - æ•´ç†è¶‹åŠ¿ä¸é£é™©\n",
      "> - ç»„ç»‡æˆæ–‡\n",
      "\n",
      "---\n",
      "\n",
      "#### 3. **å·¥å…·ä½¿ç”¨ï¼ˆTool Use / Function Callingï¼‰**\n",
      "- èƒ½è°ƒç”¨å¤–éƒ¨ API æˆ–å·¥å…·æ¥å¼¥è¡¥è‡ªèº«å±€é™ï¼ˆå¦‚æ— æ³•ç›´æ¥è®¿é—®å®æ—¶ä¿¡æ¯ï¼‰ã€‚\n",
      "- å¸¸è§å·¥å…·åŒ…æ‹¬ï¼š\n",
      "  - æµè§ˆå™¨æœç´¢ï¼ˆè·å–å®æ—¶èµ„è®¯ï¼‰\n",
      "  - ä»£ç è§£é‡Šå™¨ï¼ˆåšæ•°å­¦è®¡ç®—ã€æ•°æ®å¯è§†åŒ–ï¼‰\n",
      "  - æ–‡ä»¶è¯»å†™ï¼ˆä¿å­˜ç»“æœï¼‰\n",
      "  - æ•°æ®åº“æŸ¥è¯¢\n",
      "  - é‚®ä»¶å‘é€æ¥å£ç­‰\n",
      "\n",
      "> âœ… ç¤ºä¾‹ï¼šæŸ¥è¯¢æ±‡ç‡ã€è¿è¡Œ Python è„šæœ¬ç”»å›¾ã€ä¸‹è½½ç½‘é¡µå†…å®¹ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "#### 4. **è®°å¿†ä¸å­¦ä¹ ï¼ˆMemory Managementï¼‰**\n",
      "- **çŸ­æœŸè®°å¿†**ï¼šä¸Šä¸‹æ–‡çª—å£å†…çš„å¯¹è¯å†å²ï¼ˆç±»ä¼¼å·¥ä½œè®°å¿†ï¼‰ã€‚\n",
      "- **é•¿æœŸè®°å¿†**ï¼šé€šè¿‡å‘é‡æ•°æ®åº“å­˜å‚¨å’Œæ£€ç´¢è¿‡å¾€ç»éªŒã€çŸ¥è¯†ã€ç”¨æˆ·åå¥½ç­‰ï¼Œå®ç°è·¨ä¼šè¯è®°å¿†ã€‚\n",
      "\n",
      "> âœ… ç¤ºä¾‹ï¼šè®°ä½ä½ ä¸Šå‘¨è¯´â€œä¸å–œæ¬¢å¤ªé•¿çš„å›å¤â€ï¼Œä¸‹æ¬¡å°±ç®€æ´ä½œç­”ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### **Agent ä¸æ™®é€šèŠå¤©æœºå™¨äººçš„åŒºåˆ«**\n",
      "\n",
      "| å¯¹æ¯”é¡¹ | æ™®é€šèŠå¤©æœºå™¨äºº | Agent |\n",
      "|--------|----------------|-------|\n",
      "| æ˜¯å¦ä¸»åŠ¨æ€è€ƒ | å¦ï¼Œä»…å›åº”é—®é¢˜ | æ˜¯ï¼Œå¯è‡ªä¸»è§„åˆ’ |\n",
      "| æ˜¯å¦ä½¿ç”¨å·¥å…· | å¦ | æ˜¯ï¼ˆæœç´¢ã€ä»£ç ã€APIï¼‰ |\n",
      "| æ˜¯å¦æœ‰è®°å¿† | æœ‰é™ä¸Šä¸‹æ–‡ | æ”¯æŒé•¿æœŸè®°å¿† |\n",
      "| æ‰§è¡Œä»»åŠ¡æ–¹å¼ | è¢«åŠ¨å›ç­” | ä¸»åŠ¨å®Œæˆä»»åŠ¡ |\n",
      "| åº”ç”¨åœºæ™¯ | å®¢æœé—®ç­” | è‡ªåŠ¨åŒ–ç ”ç©¶ã€æ•°æ®åˆ†æã€ä¸ªäººåŠ©ç† |\n",
      "\n",
      "---\n",
      "\n",
      "### **ä¸¾ä¸ªå®é™…ä¾‹å­**\n",
      "\n",
      "å‡è®¾ä½ è¯´ï¼šâ€œæˆ‘æƒ³å»æ—¥æœ¬æ—…è¡Œä¸€å‘¨ï¼Œé¢„ç®— 1 ä¸‡å…ƒï¼Œè¯·å¸®æˆ‘è§„åˆ’è¡Œç¨‹ã€‚â€\n",
      "\n",
      "ä¸€ä¸ªåˆæ ¼çš„ Agent ä¼šï¼š\n",
      "1. åˆ†æä½ çš„éœ€æ±‚ï¼ˆæ—¶é—´ã€åœ°ç‚¹ã€é¢„ç®—ï¼‰\n",
      "2. æœç´¢æœºç¥¨ä»·æ ¼ã€ç­¾è¯æ”¿ç­–ã€çƒ­é—¨åŸå¸‚\n",
      "3. è§„åˆ’è·¯çº¿ï¼ˆå¦‚ä¸œäº¬ â†’ äº¬éƒ½ â†’ å¤§é˜ªï¼‰\n",
      "4. ç¼–åˆ¶æ¯æ—¥è¡Œç¨‹ + ä¼°ç®—å¼€é”€\n",
      "5. è¾“å‡º PDF è¡Œç¨‹å•ï¼Œå¹¶æé†’ä½ åŠç†ç­¾è¯\n",
      "6. å°†åå¥½å­˜å…¥é•¿æœŸè®°å¿†ï¼Œä¸‹æ¬¡æ¨èç±»ä¼¼æ—…è¡Œ\n",
      "\n",
      "---\n",
      "\n",
      "### æ€»ç»“\n",
      "\n",
      "> ğŸ” **Agent = å¤§æ¨¡å‹å¤§è„‘ + å·¥å…·æ‰‹è„š + è®°å¿†ä»“åº“ + æ¨ç†å¼•æ“**\n",
      "\n",
      "å®ƒä¸å†åªæ˜¯â€œå›ç­”é—®é¢˜â€çš„å·¥å…·ï¼Œè€Œæ˜¯èƒ½**æ›¿ä½ åŠäº‹**çš„æ•°å­—åŠ©æ‰‹ï¼Œæ˜¯è¿ˆå‘é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰çš„é‡è¦ä¸€æ­¥ã€‚\n",
      "\n",
      "æœªæ¥ï¼ŒAgent å°†æˆä¸ºæ¯ä¸ªäººçš„â€œAIå‘˜å·¥â€ï¼Œå¸®ä½ è°ƒç ”ã€å†™ä½œã€ç¼–ç¨‹ã€ç†è´¢ã€ç®¡ç†æ—¥ç¨‹â€¦â€¦çœŸæ­£å®ç°äººæœºååŒã€‚\n",
      "æ¥æº: [Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en'}, page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.')]\n"
     ]
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
