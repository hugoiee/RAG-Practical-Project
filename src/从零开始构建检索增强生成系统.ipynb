{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab688ab-ca29-42f5-9d2c-adc58a3ef261",
   "metadata": {},
   "source": [
    "# RAG系统基础:RAG系统基础：从零开始构建检索增强生成系统\n",
    "\n",
    "RAG 系统解决的问题： **模型训练知识截至日期**和**领域专业知识的缺乏**\n",
    "\n",
    "例如：在企业中询问 我们公司2025年Q3季度的销售数据是多少？（公司内部文件）\n",
    "\n",
    "# RAG系统的组成\n",
    "\n",
    "一个完整的RAG系统由三个核心组件构成：\n",
    "\n",
    "索引阶段 Indexing -> 检索阶段 Retrieval -> 生成阶段 Generation\n",
    "\n",
    "## Indexing\n",
    "\n",
    "将文档转换为可搜索的向量格式\n",
    "\n",
    "核心步骤：\n",
    "    1. 文档加载 Document Loading\n",
    "    2. 文本分块 Text Splitting\n",
    "    3. 向量化 Vectorization\n",
    "    4. 存储 Storage\n",
    "\n",
    "## Retrieval\n",
    "\n",
    "根据用户查询找到最相关的文档片段\n",
    "\n",
    "核心步骤：\n",
    "    1. 查询向量化\n",
    "    2. 相似度计算\n",
    "    3. 结果排序\n",
    "\n",
    "## Generation\n",
    "\n",
    "基于检索到的信息生成准确答案\n",
    "\n",
    "核心步骤：\n",
    "    1. 构建提示词\n",
    "    2. LLM生成\n",
    "    3. 答案返回"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 配置环境，导入核心包",
   "id": "206302ed52cacd53"
  },
  {
   "cell_type": "code",
   "id": "866fe32c-9ce8-42b6-8eea-9e5eabfcb519",
   "metadata": {},
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "\n",
    "from langchain_qwq import ChatQwQ\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9758bf9a-9445-4854-88a7-10d9e6beafa9",
   "metadata": {},
   "source": [
    "# 索引 Indexing - 构建知识库\n",
    "核心步骤：\n",
    "\n",
    "1. 文档加载 Document Loading\n",
    "2. 文本分块 Text Splitting\n",
    "3. 向量化 Vectorization\n",
    "4. 存储 Storage"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 步骤1：文档加载",
   "id": "29e4427a1b4e2697"
  },
  {
   "cell_type": "code",
   "id": "ab5e8963-71cf-4b8b-99db-a1fa9f184b90",
   "metadata": {},
   "source": [
    "# 步骤1：首先需要加载文档。LangChain支持多种文档源\n",
    "from langchain_community.document_loaders import(\n",
    "    WebBaseLoader,      # 网页\n",
    "    PyPDFLoader,        # PDF\n",
    "    TextLoader,         # 文本文件\n",
    "    DirectoryLoader,    # 目录\n",
    "    CSVLoader,          # CSV\n",
    ")\n",
    "\n",
    "# Exa: Loading Webpage\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"加载了 {len(docs)} 个文档\")\n",
    "print(f\"第一个文档长度： {(len(docs[0].page_content))} 字符\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 步骤2：文本分块\n",
    "\n",
    "为什么需要分块？\n",
    "1. LLM上下文限制：大多数LLM有最大token限制（如GPT-4的8K/32K）\n",
    "2. 提高检索精度：小块文本更容易匹配特定查询\n",
    "3. 降低成本：只检索和处理相关部分\n",
    "\n",
    "不同分块策略\n",
    "```python\n",
    "# 字符分块（最基础）\n",
    "CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# Token分块（精确控制token数量）\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "TokenTextSplitter(chunk_size=256, chunk_overlap=50)\n",
    "\n",
    "# 语义分块（基于语义相似度）\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "SemanticChunker(OpenAIEmbeddings())\n",
    "\n",
    "# 递归分块（智能识别段落）\n",
    "RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # 优先按段落分割\n",
    ")\n",
    "```"
   ],
   "id": "35b0606d51193c"
  },
  {
   "cell_type": "code",
   "id": "a6868dfc-79ba-4587-a6bb-019c4655d129",
   "metadata": {},
   "source": [
    "# 创建文本分块器\n",
    "# 递归分块（智能识别段落）\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,            # 每块最大字符数 推荐值 500-1500，太小 -> 上下文不足，太大 -> 匹配不精准\n",
    "    chunk_overlap = 200,          # 块之间的重叠 10-20% 大小，保持上下文连贯性\n",
    "    length_function = len,        # 长度计算函数\n",
    "    is_separator_regex = False,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # 分隔符：优先按段落分割，段落 > 行 > 词\n",
    ")\n",
    "\n",
    "# 分块文档\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"原始文档: {len(docs)} 个\")\n",
    "print(f\"分块后: {len(splits)} 个\")\n",
    "print(f\"\\n第一个分块示例:\\n{splits[0].page_content[:30]}...\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 步骤3：向量化\n",
    "将文本转换为数学向量，这是语义搜索的核心"
   ],
   "id": "e4031d155c330b18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 创建嵌入模型\n",
    "embeddings_model = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v4\",\n",
    ")\n",
    "\n",
    "# Exa: 向量化一段文字\n",
    "text = \"RAG是一种强大的AI技术\"\n",
    "new_vector_text = embeddings_model.embed_query(text)\n",
    "\n",
    "print(f\"文本: {text}\")\n",
    "print(f\"向量维度: {len(new_vector_text)}\")\n",
    "print(f\"向量前5个值: {new_vector_text[:5]}\")"
   ],
   "id": "379646119ed99321",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 步骤4：存储\n",
    "\n",
    "向量数据库选择：\n",
    "\n",
    "| **数据库**  | **类型** | **优势**      | **适用场景**   |\n",
    "|----------|--------|-------------|------------|\n",
    "| Chroma   | 嵌入式    | 简单易用，无需额外服务 | 开发、小规模应用 ⭐ |\n",
    "| Pinecone | 云服务    | 高性能，托管服务    | 生产环境       |\n",
    "| Weaviate | 自建     | 功能丰富，开源     | 大规模部署      |\n",
    "| FAISS    | 库      | 速度快，Meta开源  | 研究和原型      |"
   ],
   "id": "8a9afe5e44844b0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 创建向量数据库\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,           # 分块后的文档\n",
    "    embedding=embeddings_model,       # 嵌入模型\n",
    "    persist_directory=\"./chroma_db\"  # 持久化目录\n",
    ")\n",
    "\n",
    "print(f\"✅ 向量数据库创建成功！\")\n",
    "print(f\"   存储了 {len(splits)} 个文档块\")\n",
    "print(f\"   持久化路径: ./chroma_db_\")"
   ],
   "id": "44507fc0a74a102f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 完整流程 + 封装",
   "id": "35f222dac569c051"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_vectorstore(url: str, chunk_size: int = 1000):\n",
    "    \"\"\"创建向量数据库\"\"\"\n",
    "\n",
    "    # 1. 加载文档\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "\n",
    "    # 2. 分块\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=int(chunk_size * 0.1)\n",
    "    )\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    # 3. 向量化并存储\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=splits,\n",
    "        embedding=DashScopeEmbeddings(model=\"text-embedding-v4\"),\n",
    "        persist_directory=f\"./chroma_db_{url.split('/')[-1]}\"\n",
    "    )\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "# 使用\n",
    "vectorstore = create_vectorstore(\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
    ")"
   ],
   "id": "479005c827d8d42d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
